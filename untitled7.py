# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xPJNbXE5O_b5mkgXo5JWiPoRzsQdwjRH
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import VotingClassifier
import matplotlib.pyplot as plt
import numpy as np

# Load the loan prediction dataset
data = pd.read_csv('Micro-credit-Data-file.csv')

# Drop missing values
data = data.dropna()
data = data.head(1000)
data = pd.get_dummies(data, columns=['msisdn'], drop_first=True)
data = pd.get_dummies(data, columns=['pcircle'], drop_first=True)
data = pd.get_dummies(data, columns=['pdate'], drop_first=True)
# Define the features and the target variable
X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

# Split the data into a training set and a test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# Define the models
models = [
    RandomForestClassifier(),
    GradientBoostingClassifier(),
    LogisticRegression(),
    SVC(probability = True),
    MLPClassifier()
]

# Hyperparameter tuning
hyperparameters = {
    RandomForestClassifier: {
        'n_estimators': [100, 200, 300],
        'max_depth': [5, 10, 15]
    },
    GradientBoostingClassifier: {
        'n_estimators': [100, 200, 300],
        'max_depth': [5, 10, 15],
        'learning_rate': [0.1, 0.01, 0.001]
    },
    LogisticRegression: {
        'C': [0.1, 1, 10]
    },
    SVC: {
        'C': [0.1, 1, 10],
        'kernel': ['linear', 'rbf', 'poly']
    },
    MLPClassifier: {
        'hidden_layer_sizes': [(100, 50), (150, 75), (200, 100)],
        'activation': ['relu', 'tanh', 'leaky_relu']
    }
}
# Create a voting classifier
voting_clf = VotingClassifier(estimators=[(model.__class__.__name__, model) for model in models], voting='soft')
voting_clf.fit(X_train, y_train)

# Make predictions on the test set with probabilities
y_pred_proba = voting_clf.predict_proba(X_test)

# Calculate the probability of the positive class for each data sample
prob_positive = y_pred_proba[:, 1]

# Identify data samples that are likely to be positive
positive_samples = np.where(prob_positive > 0.5, True, False)

# Train and evaluate the models
results = []
for model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    y_pred = getattr(model, 'predict')(X_test)
    log_loss = -np.mean(y_test * np.log(getattr(model, 'predict_proba')(X_test)[:, 1]) + (1 - y_test) * np.log(1 - getattr(model, 'predict_proba')(X_test)[:, 1]))

    results.append({
        'model': model.__class__.__name__,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'log_loss': log_loss
    })

# Make predictions on the test set
y_pred = voting_clf.predict(X_test)

# Print the model performance
print('Voting classifier performance:')
print(f'Accuracy: {accuracy:.3f}')
print(f'Precision: {precision:.3f}')
print(f'Recall: {recall:.3f}')
print(f'Log loss: {log_loss:.3f}')

plt.bar(['Accuracy', 'Precision', 'Recall','Log loss'], [accuracy, precision, recall, log_loss,])
plt.title('Voting Classifier Test Set Performance')
plt.xlabel('Metric')
plt.ylabel('Score')
plt.show()

# Sort the results by accuracy
results.sort(key=lambda x: x['accuracy'], reverse=True)

# Print the top 5 results
print('Top 5 models by accuracy:')
for result in results[:5]:
    print(f'{result["model"]} - Accuracy: {result["accuracy"]:.3f}')